#  关联分析介绍
商场的销售过程，涉及很多机器学习的应用，商品的陈列，购物卷的提供，用户忠诚度等等，通过对这些大量数据的分析，可以帮组商店了解用户的购物行为，进而对商品的定价、市场促销、存货管理等进行决策。
从大规模数据集中寻找物品间的隐含关系被称作关联分析（association analysis）或者关联规则学习（association rule learning）。这里的主要问题在于，寻找物品的不同组合是一项十分耗时的任务，所需的计算代价很高，蛮力搜索方法并不能解决这个问题，所以需要用更智能的方法在合理的时间范围内找到频繁项集。
这些关系可以有两种形式：频繁项集、关联规则。
频繁项集：经常出现在一块的物品的集合
关联规则：暗示两种物品之间可能存在很强的关系
一个具体的例子：

 

频繁项集是指那些经常出现在一起的物品，例如上图的{葡萄酒、尿布、豆奶}，从上面的数据集中也可以找到尿布->葡萄酒的关联规则，这意味着有人买了尿布，那很有可能他也会购买葡萄酒。那如何定义和表示频繁项集和关联规则呢？这里引入支持度和可信度（置信度）。

##  支持度：一个项集的支持度被定义为数据集中包含该项集的记录所占的比例，上图中，豆奶的支持度为4/5，（豆奶、尿布）为3/5。支持度是针对项集来说的，因此可以定义一个最小支持度，只保留最小支持度的项集。

##  可信度（置信度）：针对如{尿布}->{葡萄酒}这样的关联规则来定义的。计算为 支持度{尿布，葡萄酒}/支持度{尿布}，其中{尿布，葡萄酒}的支持度为3/5，{尿布}的支持度为4/5，所以“尿布->葡萄酒”的可行度为3/4=0.75，这意味着尿布的记录中，我们的规则有75%都适用。

有了可以量化的计算方式，我们却还不能立刻运算，这是因为如果我们直接运算所有的数据，运算量极其的大，很难实现，这里说明一下，假设我们只有 4 种商品：商品0，商品1，商品 2，商品3. 那么如何得可能被一起购买的商品的组合？
一杂货店有四种商品 0，1，2，3.这些商品的组合可能有一种，二种，三种，四种。我们的关注点：用户购买一种或者多种商品，不关心具体买的商品的数量。
集合{0，1，2，3}中所有可能的项集组合如下图
 


 

四种商品要遍历15次，随着物品数目的增加遍历次数会急剧增加。对于包含N种商品的数据集一共有2^N-1种项集组合。

上图显示了物品之间所有可能的组合，从上往下一个集合是 Ø，表示不包含任何物品的空集，物品集合之间的连线表明两个或者更多集合可以组合形成一个更大的集合。我们的目标是找到经常在一起购买的物品集合。这里使用集合的支持度来度量其出现的频率。一个集合出现的支持度是指有多少比例的交易记录包含该集合。例如，对于上图，要计算 0,3 的支持度，直接的想法是遍历每条记录，统计包含有 0 和 3 的记录的数量，使用该数量除以总记录数，就可以得到支持度。而这只是针对单个集合 0,3. 要获得每种可能集合的支持度就需要多次重复上述过程。对于上图，虽然仅有4中物品，也需要遍历数据15次。随着物品数目的增加，遍历次数会急剧增加，对于包含 N 种物品的数据集共有 2^N−1 种项集组合。为了降低计算时间，研究人员发现了 Apriori 原理，可以帮我们减少感兴趣的频繁项集的数目。

#  Apriori 的原理：
##  定律1： 
              如果一个集合是频繁项集，则它的所有子集都是频繁项集。 
举例：假设一个集合{A,B}是频繁项集，即A、B同时出现在一条记录的次数大于等于最小支持度min_support，则它的子集{A},{B}出现次数必定≧min_support，即它的子集都是频繁项集。
##  定律2： 
              如果一个集合不是频繁项集，则它的所有超集都不是频繁项集。 
举例：假设集合{A}不是频繁项集，即A出现的次数小于min_support，则它的任何超集如{A,B}出现的次数必定小于（min_support），因此其超集必定也不是频繁项集。
注意： 
              由二级频繁项集生成三级候选项集时，没有{牛奶,面包,啤酒}，那是因为{面包,啤酒}不是二级频繁项集。 
              最后生成三级频繁项集后，没有更高一级的候选项集，算法结束，{牛奶,面包,尿布}是最大频繁子集。
如下图所示：


 


Apriori算法是经典生成关联规则的频繁项集挖掘算法，其目标是找到最多的K项频繁集。那么什么是最多的K项频繁集呢？例如当我们找到符合支持度的频繁集AB和ABE，我们会选择3项频繁集ABE。下面我们介绍Apriori算法选择频繁K项集过程。

Apriori算法采用迭代的方法，先搜索出候选1项集以及对应的支持度，剪枝去掉低于支持度的候选1项集，得到频繁1项集。然后对剩下的频繁1项集进行连接，得到候选2项集，筛选去掉低于支持度的候选2项集，得到频繁2项集。如此迭代下去，直到无法找到频繁k+1集为止，对应的频繁k项集的集合便是算法的输出结果。我们可以通过下面例子来看到具体迭代过程。
 
 
数据集包含4条记录{‘134’,‘235’,‘1235’,‘25’}，我们利用Apriori算法来寻找频繁k项集，最小支持度设置为50%。首先生成候选1项集，共包含五个数据{‘1’,‘2’,‘3’,‘4’,‘5’}，计算5个数据的支持度，然后对低于支持度的数据进行剪枝。其中数据{4}支持度为25%，低于最小支持度，进行剪枝处理，最终频繁1项集为{‘1’,‘2’,‘3’,‘5’}。根据频繁1项集连接得到候选2项集{‘12’,‘13’,‘15’,‘23’,‘25’,‘35’}，其中数据{‘12’,‘15’}低于最低支持度，进行剪枝处理，得到频繁2项集为{‘13’,‘23’,‘25’,‘35’}。如此迭代下去，最终能够得到频繁3项集{‘235’}，由于数据无法再进行连接，算法至此结束。

#  Apriori算法流程

从Apriori算法原理中我们能够总结如下算法流程，其中输入数据为数据集合D和最小支持度α，输出数据为最大的频繁k项集。
扫描数据集，得到所有出现过的数据，作为候选1项集。
挖掘频繁k项集。
扫描计算候选k项集的支持度。
剪枝去掉候选k项集中支持度低于最小支持度α的数据集，得到频繁k项集。如果频繁k项集为空，则返回频繁k-1项集的集合作为算法结果，算法结束。如果得到的频繁k项集只有一项，则直接返回频繁k项集的集合作为算法结果，算法结束。
基于频繁k项集，连接生成候选k+1项集。
利用步骤2，迭代得到k=k+1项集结果。





#  从频繁集中挖掘相关规则
解决了频繁项集问题，下一步就可以解决相关规则问题。
要找到关联规则，我们首先从一个频繁项集开始。从杂货店的例子可以得到，如果有一个频繁项集{豆奶, 莴苣}，那么就可能有一条关联规则“豆奶➞莴苣”。这意味着如果有人购买了豆奶，那么在统计上他会购买莴苣的概率较大。注意这一条反过来并不总是成立，也就是说，可信度(“豆奶➞莴苣”)并不等于可信度(“莴苣➞豆奶”)。
前文也提到过，一条规则P➞H的可信度定义为support(P | H)/support(P)，其中“|”表示P和H的并集。可见可信度的计算是基于项集的支持度的。
图4给出了从项集{0,1,2,3}产生的所有关联规则，其中阴影区域给出的是低可信度的规则。可以发现如果{0,1,2}➞{3}是一条低可信度规则，那么所有其他以3作为后件（箭头右部包含3）的规则均为低可信度的。



 


#  Apriori算法优缺点

##  优点
适合稀疏数据集。
算法原理简单，易实现。
适合事务数据库的关联规则挖掘。
##  缺点
可能产生庞大的候选集。
算法需多次遍历数据集，算法效率低，耗时。
